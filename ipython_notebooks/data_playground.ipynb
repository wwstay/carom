{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import cPickle as pk\n",
    "import pdb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class properties:\n",
    "    def __init__(self, db, name):\n",
    "        self.name=name\n",
    "        self.dat = pd.DataFrame(list(db.find()))\n",
    "        if os.path.isfile(self.name+\"_params.pk\"):\n",
    "            self.params = pk.load(open(self.name+\"_params.pk\",\"rb\"))        \n",
    "        self.stop_words= pk.load(open(\"stop_words.pk\",\"rb\"))\n",
    "        \n",
    "    def benchmark(self):\n",
    "        if os.path.isfile(self.name+\"_params.pk\"):\n",
    "            return self.params\n",
    "        else:\n",
    "            self.params = self.analyze()\n",
    "            self.params['latitude'] = self.dat[self.get_relevcols('latitude')]\n",
    "            self.params['longitude'] = self.dat[self.get_relevcols('longitude')]\n",
    "            self.params['city'] = self.dat['city']\n",
    "            #print self.params\n",
    "            print \"Writing to: \", self.name + \"_parameters.scsv\" \n",
    "            self.params.to_csv(self.name+\"_parameters.scsv\",encoding='utf-8',index=False,sep=';')\n",
    "            print \"Writing to: \", self.name + \"_parameters.pk\"\n",
    "            pk.dump(self.params,open(self.name+\"_params.pk\",\"wb\"))\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def get_relevcols(self, colname):\n",
    "        return [col for col in self.dat.columns.values.str.lower() if colname in col.lower()]\n",
    "    \n",
    "    def get_df(self):\n",
    "        #Extract column names\n",
    "        sve_col = [col for col in self.dat.columns.values if 'name' in col.lower() or 'address' in col.lower() or 'latitude' in col.lower() or 'longitude' in col.lower() or \"city\" in col.lower()]\n",
    "        sve_col.append('location')\n",
    "        \n",
    "        #Extract columns\n",
    "        ndf = pd.DataFrame([self.dat[ccol].str.lower() if 'name' in ccol.lower() or 'address' in ccol.lower() or 'city' in ccol.lower() else self.dat[ccol] for ccol in sve_col]).T\n",
    "        ndf.columns = map(unicode.lower, ndf.columns)\n",
    "        return ndf\n",
    "    \n",
    "    def analyze(self):\n",
    "        #Get name and address data\n",
    "        namedat = self.dat[self.get_relevcols('name')]\n",
    "        addr_dat = self.dat[self.get_relevcols('address')]\n",
    "\n",
    "        #Create dataframe\n",
    "        prop_data = pd.DataFrame({\"name_bigrams\": gramsplitter(namedat,2),\n",
    "                                  \"address_trigrams\": gramsplitter(addr_dat,3)})\n",
    "\n",
    "        return prop_data\n",
    "    \n",
    "    def gramclean(self,x):\n",
    "        if x.isnull().all():\n",
    "            return np.nan\n",
    "        return ' '.join([word for word in x.str.replace('[^\\w\\s]','').str.split().tolist()[0] if word not in self.stop_words])\n",
    "    \n",
    "    #Clean data frame and generate ngrams\n",
    "    def gramsplitter(self,df,n):\n",
    "        df = df.apply(gramclean,axis=1)\n",
    "        return df.map(lambda x: x if (isinstance(x,float)) else self.ngrammer(x.split(\" \"),n))\n",
    "    \n",
    "    def ngrammer(self,inplis, n):\n",
    "        if len(inplis)<1:\n",
    "            return np.nan\n",
    "        return list(zip(*[inplis[i:] for i in range(n)]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_relevcols() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-00c4473b6be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobj_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mean_properties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-f186dde7b62c>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-f186dde7b62c>\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#Get name and address data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnamedat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0maddr_dat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_relevcols() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "obj_ = properties(db.ean_properties,\"ean\")\n",
    "obj_.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevcols(df, colname):\n",
    "\treturn [col for col in df.columns.values if colname in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump4bigram(*args):\n",
    "\tfor idx,subdf in enumerate(args):\n",
    "\t\tsubdf[get_relevcols(subdf, 'name')].to_csv(repr(idx)+\"_names.txt\",sep='\\n',encoding='utf-8',index=False,header=False)\n",
    "\t\tsubdf[get_relevcols(subdf, 'address')].to_csv(repr(idx)+\"_address.txt\",sep='\\n',encoding='utf-8',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokener(textS):\n",
    "\t#Remove punctuation\n",
    "\tdef splitter(txt):\n",
    "\t\ttx1 = txt.str.replace('[^\\w\\s]','')\n",
    "\t\treturn tx1.str.split()\n",
    "\t\n",
    "\ttdat = textS.apply(splitter,axis=1)\n",
    "\ttdatS = pd.Series(tdat.squeeze(),index=tdat.index)\n",
    "\t#Flatten Series\n",
    "\tflattdat = [item for sublist in tdatS.tolist() for item in sublist]\n",
    "\t#Get english+french+german stopwords (such as and, or, is, the, a etc.)\n",
    "\teng_stop_words = set(stopwords.words(\"english\")+['test','1234','various','addresses'])\n",
    "\tfr_stop_words = set(stopwords.words(\"french\"))\n",
    "\tger_stop_words = set(stopwords.words(\"german\"))\n",
    "\tstop_wrds = eng_stop_words.union(fr_stop_words).union(ger_stop_words)\n",
    "\t\n",
    "\t#Remove all such stopwords\n",
    "\tflattdat = [w for w in flattdat if w.lower() not in stop_wrds]\n",
    "\n",
    "\treturn flattdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exploretext(textS,nme):\n",
    "\t#Tokenize data\n",
    "\tflattdat = tokener(textS)\n",
    "\tnltext = nltk.Text(flattdat)\n",
    "\t\n",
    "\t#Print most common bigrams\n",
    "\tprint nltext.collocations()\n",
    "\t\n",
    "\t#Plot cumulative frequency distribution of words\n",
    "\tfdistr = nltk.FreqDist(nltext)\n",
    "\tfdistr.plot(50,cumulative=True)\n",
    "\tplt.savefig(\"cuml_freq_indvwords_\"+nme+\".png\")\n",
    "\tplt.close()\n",
    "\n",
    "\t#Plot freq distribution of number of letters in a token present\n",
    "\tlettfdistr = nltk.FreqDist([len(w) for w in nltext])\n",
    "\tlettfdistr.plot(50)\n",
    "\tplt.savefig(\"letr_freq_\"+nme+\".png\")\n",
    "\tplt.close()\n",
    "\n",
    "\t#Plot bigrams \n",
    "\tnlbigrams = list(nltk.bigrams(flattdat))\n",
    "\tprint nlbigrams[:50]\n",
    "\tfd = nltk.FreqDist(nlbigrams)\n",
    "\tfd.plot(10, cumulative=True)\n",
    "\tplt.savefig(\"bigram_freq_\"+nme+\".png\")\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produce n gram\n",
    "def ngrammer(inplis, n):\n",
    "\tif len(inplis)<1:\n",
    "\tprint namedat\treturn np.nan\n",
    "\treturn list(zip(*[inplis[i:] for i in range(n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean data frame and generate ngrams\n",
    "def gramsplitter(df,n):\n",
    "\teng_stop_words = set(stopwords.words(\"english\")+['test','1234','various','addresses'])\n",
    "\tfr_stop_words = set(stopwords.words(\"french\"))\n",
    "\tger_stop_words = set(stopwords.words(\"german\"))\n",
    "\tstop_wrds = eng_stop_words.union(fr_stop_words).union(ger_stop_words)\n",
    "\t\n",
    "\tdef gramclean(x):\n",
    "\t\tif x.isnull().all():\n",
    "\t\t\treturn np.nan\n",
    "\t\treturn ' '.join([word for word in x.str.replace('[^\\w\\s]','').str.split().tolist()[0] if word not in stop_wrds])\n",
    "\n",
    "\tdf = df.apply(gramclean,axis=1)\n",
    "\treturn df.map(lambda x: x if (isinstance(x,float)) else ngrammer(x.split(\" \"),n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze(dat):\n",
    "\t#Get name and address data\n",
    "\tnamedat = dat[get_relevcols(dat,'name')]\n",
    "\taddr_dat = dat[get_relevcols(dat,'address')]\n",
    "\n",
    "\t#exploretext(namedat,\"name\")\n",
    "\t\n",
    "\t#exploretext(addr_dat,\"addr\")\n",
    "\t\n",
    "\t#Create dataframe\n",
    "\tprop_data = pd.DataFrame({\"name_bigrams\": gramsplitter(namedat,2),\n",
    "\t\t\t\t\t\t\t  \"address_trigrams\": gramsplitter(addr_dat,3)})\n",
    "\n",
    "\treturn prop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createparams(db_props,propname):\n",
    "    prop_dat= pd.DataFrame(list(db_props.find()))\n",
    "    #hot_beds = pd.DataFrame(list(db.hotelbeds_properties.find()))\n",
    "    colrmv = [\"verification\",\"verified\",\"mapped_to\",\"mapped_to_ext_id\"]\n",
    "    #prop_dat.drop(colrmv,axis=1,inplace=True)\n",
    "\n",
    "    prop_subdf = get_df(prop_dat)\n",
    "    #print prop_subdf.columns\n",
    "    prop_subdf = prop_subdf.join(prop_dat[colrmv])\n",
    "    prop_params = analyze(prop_subdf)\n",
    "    prop_params['latitude'] = prop_subdf[get_relevcols(prop_subdf,'latitude')]\n",
    "    prop_params['longitude'] = prop_subdf[get_relevcols(prop_subdf,'longitude')]\n",
    "    prop_params['city'] = prop_subdf['city']\n",
    "    prop_params[colrmv] = prop_subdf[colrmv]\n",
    "    print prop_params.head()\n",
    "    prop_params.to_csv(propname+\"_parameters.scsv\",encoding='utf-8',index=False,sep=';')\n",
    "    pk.dump(prop_params,open(propname+\"_params.pk\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(db):\n",
    "    createparams(db.hotelbeds_properties,\"hotelbeds\")\n",
    "    createparams(db.taap_properties,\"taap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client['supplier_static_database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findidx(StemWords,word):\n",
    "    A = []\n",
    "    for key,value in StemWords.items():\n",
    "        if word in value:\n",
    "            return key\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemmer(x,stemdic,stopwords):\n",
    "    tokens = x.replace('[^\\w\\s]','').split()\n",
    "    for idx,word in enumerate(tokens):\n",
    "        if word in stopwords:\n",
    "            del tokens[idx]\n",
    "            continue\n",
    "        tokens[idx] = findidx(stemdic.loc[stemdic.index.str.startswith(word[0])],word)\n",
    "    return tokens            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_stop_words = set(stopwords.words(\"english\")+['test','1234','various','addresses'])\n",
    "fr_stop_words = set(stopwords.words(\"french\"))\n",
    "ger_stop_words = set(stopwords.words(\"german\"))\n",
    "stop_words = eng_stop_words.union(fr_stop_words).union(ger_stop_words)\n",
    "pk.dump(stop_words,open(\"stop_words.pk\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_subdf= pd.DataFrame(list(db.hotelbeds_properties.find()))\n",
    "prop_subdf.columns = map(unicode.lower, prop_subdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                         inter-burgo ansan\n",
      "1                                          dogo glory condo\n",
      "2                                                   w hotel\n",
      "3                                        onyang grand hotel\n",
      "4                                   onyang hot spring hotel\n",
      "5              onyang cheil hotel (ex. onyang palace hotel)\n",
      "6                  springhill suites paso robles atascadero\n",
      "7                              best western plus colony inn\n",
      "8                                                    hesse \n",
      "9                                   ibis styles aachen city\n",
      "10                                pullman aachen quellenhof\n",
      "11                               mercure aachen europaplatz\n",
      "12                                    leonardo hotel aachen\n",
      "13                                    aquis grana cityhotel\n",
      "14                                              buschhausen\n",
      "15                                      novotel aachen city\n",
      "16                        domicil residenz hotel bad aachen\n",
      "17                                                  baccara\n",
      "18                                    rosenpark-laurensberg\n",
      "19                              mercure hotel aachen am dom\n",
      "20                                        harzer land hotel\n",
      "21                                 ibis aachen hauptbahnhof\n",
      "22                                  a&o aachen hauptbahnhof\n",
      "23                               best western hotel regence\n",
      "24                                 best western hotel royal\n",
      "25                              best western hotel de ville\n",
      "26                                           hotel lousberg\n",
      "27                                 zum harzer jodlermeister\n",
      "28                        hotelferienanlage friedrichsbrunn\n",
      "29                                                friedrich\n",
      "                                ...                        \n",
      "166265                             aparthotel castrum novum\n",
      "166266                                            trakoscan\n",
      "166267                               crowne plaza zhangzhou\n",
      "166268                                          tatry apart\n",
      "166269                holiday inn express and suites zapata\n",
      "166270                    holiday inn express foshan nanhai\n",
      "166271                                       sofitel foshan\n",
      "166272    holiday inn express and suites chicago north w...\n",
      "166273                                    fair resort & spa\n",
      "166274                                    azao resort & spa\n",
      "166275                                    dongwe ocean view\n",
      "166276                                  nyamkwi white sands\n",
      "166277                               the sands beach resort\n",
      "166278                                 shaba boutique hotel\n",
      "166279                         golden tulip zanzibar resort\n",
      "166280                                        mazsons hotel\n",
      "166281    holiday inn express and suites petersburg dinw...\n",
      "166282                holiday inn petersburg north fort lee\n",
      "166283    holiday inn express and suites petersburg fort...\n",
      "166284                         holiday inn richmond airport\n",
      "166285         candlewood suites ft lee petersburg hopewell\n",
      "166286    holiday inn express and suites richmond north ...\n",
      "166287            candlewood suites colonial heights ft lee\n",
      "166288    holiday inn express and suites thornburg s. fr...\n",
      "166289    holiday inn express richmond i 64 short pump area\n",
      "166290                                       cronulla hotel\n",
      "166291          villas cavo marathia 4* apartments - one br\n",
      "166292     villas cavo marathia 4* apartments - one br no.2\n",
      "166293                       holiday inn zhongshan downtown\n",
      "166294     garland hotel, an ascend hotel collection member\n",
      "Name: Name, Length: 166295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "namedat=prop_subdf[get_relevcols(prop_subdf,'name')].iloc[:,0].str.lower()\n",
    "print namedat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemingdic = pd.read_csv(\"stemming_dict.csv\",header=None,index_col=False)\n",
    "stemingdic.index = stemingdic[0]\n",
    "stemingdic = stemingdic.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [inter-burgo, ansan]\n",
       "1                                      [dogo, glory, condo]\n",
       "2                                                [w, hotel]\n",
       "3                                    [onyang, grand, hotel]\n",
       "4                              [onyang, hot, spring, hotel]\n",
       "5         [onyang, cheil, hotel, None, onyang, palace, h...\n",
       "6            [springhill, suites, paso, robles, atascadero]\n",
       "7                        [best, western, plus, colony, inn]\n",
       "8                                                   [hesse]\n",
       "9                              [ibis, styles, aachen, city]\n",
       "10                                  [pullman, aachen, None]\n",
       "11                           [mercure, aachen, europaplatz]\n",
       "12                                [leonardo, hotel, aachen]\n",
       "13                                [aquis, grana, cityhotel]\n",
       "14                                            [buschhausen]\n",
       "15                                  [novotel, aachen, city]\n",
       "16                  [domicil, residenz, hotel, bad, aachen]\n",
       "17                                                [baccara]\n",
       "18                                  [rosenpark-laurensberg]\n",
       "19                            [mercure, hotel, aachen, dom]\n",
       "20                                    [harzer, land, hotel]\n",
       "21                             [ibis, aachen, hauptbahnhof]\n",
       "22                              [a&o, aachen, hauptbahnhof]\n",
       "23                          [best, western, hotel, regence]\n",
       "24                            [best, western, hotel, royal]\n",
       "25                            [best, western, hotel, ville]\n",
       "26                                        [hotel, lousberg]\n",
       "27                                  [harzer, jodlermeister]\n",
       "28                     [hotelferienanlage, friedrichsbrunn]\n",
       "29                                              [friedrich]\n",
       "                                ...                        \n",
       "166265                         [aparthotel, castrum, novum]\n",
       "166266                                          [trakoscan]\n",
       "166267                                [crowne, plaza, None]\n",
       "166268                                       [tatry, apart]\n",
       "166269                [holiday, inn, express, suites, None]\n",
       "166270              [holiday, inn, express, foshan, nanhai]\n",
       "166271                                    [sofitel, foshan]\n",
       "166272    [holiday, inn, express, suites, chicago, n, wa...\n",
       "166273                            [fair, resort, None, spa]\n",
       "166274                            [azao, resort, None, spa]\n",
       "166275                                [dongwe, ocean, view]\n",
       "166276                              [nyamkwi, white, sands]\n",
       "166277                                 [sands, bch, resort]\n",
       "166278                             [shaba, boutique, hotel]\n",
       "166279                        [golden, tulip, None, resort]\n",
       "166280                                     [mazsons, hotel]\n",
       "166281    [holiday, inn, express, suites, petersburg, di...\n",
       "166282             [holiday, inn, petersburg, n, fort, lee]\n",
       "166283    [holiday, inn, express, suites, petersburg, fo...\n",
       "166284                    [holiday, inn, richmond, airport]\n",
       "166285    [candlewood, suites, ft, lee, petersburg, hope...\n",
       "166286    [holiday, inn, express, suites, richmond, n, a...\n",
       "166287     [candlewood, suites, colonial, heights, ft, lee]\n",
       "166288    [holiday, inn, express, suites, thornburg, s.,...\n",
       "166289    [holiday, inn, express, richmond, 64, short, p...\n",
       "166290                                    [cronulla, hotel]\n",
       "166291    [villas, cavo, marathia, None, apartments, Non...\n",
       "166292    [villas, cavo, marathia, None, apartments, Non...\n",
       "166293                       [holiday, inn, None, downtown]\n",
       "166294    [garland, hotel,, ascend, hotel, collection, m...\n",
       "Name: Name, Length: 166295, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namedat.apply(stemmer,args=(stemingdic,stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gramclean(x,stop_words):\n",
    "\t\tif x.isnull().all():\n",
    "\t\t\treturn np.nan\n",
    "\t\treturn ' '.join([word for word in x.str.replace('[^\\w\\s]','').str.split().tolist()[0] if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
